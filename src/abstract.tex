Per un \textbf{Robot} è cruciale mantenere un'aggiornata \textbf{rappresentazione del proprio ambiente} per poter prendere decisioni e controllare il proprio comportamento. Recentemente, i Large Language Models sono stati integrati all'interno dei robot per permettere ulteriori interazioni con l'essere umano. Questi devono essere in grado di fare reasoning su una certa rappresentazione dell'ambiente.
In questa tesi verrà presentato un approccio per la \textbf{percezione dell'ambiente} e l'integrazione delle informazioni del sensore all'interno della \textbf{base di conoscenza} di RoBee, \textbf{robot umanoide} di Oversonic Robotics. Questa base di conoscenza è a supporto del sistema di \textbf{Mission Planning}, che attraverso degli agenti LLM permette a RoBee di tradurre le richieste in linguaggio naturale dell'utente in missioni per il robot.
La \textbf{Mappa Semantica} è un'astrazione dell'ambiente circostante, che permette di rappresentare le informazioni semantiche riguardo a \textbf{oggetti e stanze} in un \textbf{grafo} con diversi tipi di nodi e archi che rappresentano le relazioni tra nodi oggetto oppure collegamenti tra nodi stanza.
Il sistema di percezione dell'ambiente è composto da due moduli principali: il \textbf{riconoscimento delle stanze} e la \textbf{generazione del grafo di scena}. Il primo individua le stanze data la mappa di occupazione dell'ambiente, mentre il secondo individua gli oggetti e le relazioni tra loro grazie a un modello di Deep Learning.
Questo primitivo sistema di mappatura semantica dell'ambiente consente a RoBee di ottenere informazioni aggiornate riguardo gli oggetti presenti nella mappa in modo efficiente e adatto al contesto real time.
Il sistema è stato testato in un contesto reale e i risultati ottenuti riguardo la creazione e l'aggiornamento della base di conoscenza sono stati soddisfacenti.

\chapter*{Abstract}
For a \textbf{robot} it is crucial to maintain an updated \textbf{representation of its environment} in order to make decisions and control its behavior. Recently, Large Language Models have been integrated into robots to allow further interactions with humans. These must be able to reason about a certain representation of the environment.
In this thesis, an approach for \textbf{environment perception} and the integration of sensor information into the \textbf{knowledge base} of RoBee, an Oversonic Robotics humanoid robot, will be presented. This knowledge base supports the \textbf{Mission Planning} system, which through LLM agents allows RoBee to translate user requests in natural language into missions for the robot.
The \textbf{Semantic Map} is an abstraction of the surrounding environment, which allows to represent semantic information about \textbf{objects and rooms} in a \textbf{graph} with different types of nodes and edges that represent the relationships between object nodes or connections between room nodes.
The environment perception system consists of two main modules: \textbf{room recognition} and \textbf{scene graph generation}. The first one identifies the rooms given the occupancy map of the environment, while the second one identifies the objects and the relationships between them thanks to a Deep Learning model.
This primitive environment semantic mapping system allows RoBee to obtain updated information about the objects present in the map efficiently and suitable for real-time context.
The system has been tested in a real context and the results obtained regarding the creation and updating of the knowledge base have been satisfactory.